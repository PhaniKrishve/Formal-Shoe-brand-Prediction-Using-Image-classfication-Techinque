{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir(\"C:\\\\Users\\\\Administrator\\\\project_internship\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "classfier=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convlution layer\n",
    "classfier.add(Conv2D(64,(3,3),input_shape=(40,40,3),activation='relu'))\n",
    "\n",
    "#max pooling\n",
    "classfier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "\n",
    "#Convlution layer\n",
    "classfier.add(Conv2D(64,(3,3),activation='relu'))\n",
    "\n",
    "#max pooling\n",
    "classfier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#Add another layer\n",
    "classfier.add(Conv2D(64,(3,3),activation='relu'))\n",
    "\n",
    "#max pooling\n",
    "classfier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "classfier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dense layer\n",
    "classfier.add(Dense(units=150,activation='relu'))\n",
    "classfier.add(Dense(units=150,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "classfier.add(Dense(units=3,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator as I\n",
    "train_datagen=I(rescale=.1/255,\n",
    "               shear_range=0.2,\n",
    "               zoom_range=0.2,\n",
    "               horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = I(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "classfier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 614 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_set = train_datagen.flow_from_directory('dataset/train',\n",
    "                                               target_size=(40,40),\n",
    "                                               batch_size=500,\n",
    "                                               class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bata': 0, 'clarks': 1, 'leecooper': 2}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 174 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('dataset/test',\n",
    "                                            target_size=(40, 40),\n",
    "                                            batch_size=80,\n",
    "                                            class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor = 'val_acc', # value being monitored for improvement\n",
    "                          min_delta = 0, #Abs value and is the min change required before we stop\n",
    "                          patience = 15, #Number of epochs we wait before stopping \n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "callbacks = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 31s 3s/step - loss: 1.0812 - acc: 0.4476 - val_loss: 1.4311 - val_acc: 0.4543\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 19s 2s/step - loss: 1.0707 - acc: 0.4530 - val_loss: 2.6922 - val_acc: 0.4539\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 22s 2s/step - loss: 1.0715 - acc: 0.4425 - val_loss: 1.5634 - val_acc: 0.4539\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 22s 2s/step - loss: 1.0562 - acc: 0.4604 - val_loss: 1.8865 - val_acc: 0.4537\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 21s 2s/step - loss: 1.0426 - acc: 0.4573 - val_loss: 2.0491 - val_acc: 0.4547\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 22s 2s/step - loss: 1.0338 - acc: 0.4698 - val_loss: 1.6193 - val_acc: 0.4651\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 20s 2s/step - loss: 1.0133 - acc: 0.4985 - val_loss: 2.9052 - val_acc: 0.4765\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 20s 2s/step - loss: 1.0040 - acc: 0.5068 - val_loss: 1.2874 - val_acc: 0.4898\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.9752 - acc: 0.5296 - val_loss: 2.3455 - val_acc: 0.4991\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.9903 - acc: 0.5074 - val_loss: 2.6819 - val_acc: 0.5237\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.9616 - acc: 0.5321 - val_loss: 1.9500 - val_acc: 0.5106\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.9464 - acc: 0.5248 - val_loss: 1.7390 - val_acc: 0.5574\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.9249 - acc: 0.5402 - val_loss: 2.4689 - val_acc: 0.5115\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.8981 - acc: 0.5822 - val_loss: 3.0538 - val_acc: 0.4762\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.8796 - acc: 0.5949 - val_loss: 2.3231 - val_acc: 0.5743\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.8300 - acc: 0.6130 - val_loss: 2.9501 - val_acc: 0.5404\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.8214 - acc: 0.6325 - val_loss: 2.6718 - val_acc: 0.5578\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.7872 - acc: 0.6400 - val_loss: 3.0456 - val_acc: 0.5686\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.7729 - acc: 0.6423 - val_loss: 2.9602 - val_acc: 0.5745\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.7539 - acc: 0.6514 - val_loss: 3.6364 - val_acc: 0.5749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20181816d30>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classfier.fit_generator(\n",
    "        train_set,\n",
    "        steps_per_epoch=10,\n",
    "        epochs=20,\n",
    "        #callbacks = callbacks,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json=classfier.to_json()\n",
    "with open(\"formal_shoe_with_early_stopping_epoch_10.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "classfier.save_weights(\"formal_shoe_with_early_stopping_epoch_10.h5\")\n",
    "print(\"save model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bata105.jpg-----Bata\n",
      "Bata115.jpg-----Bata\n",
      "Bata125.jpg-----Leecooper\n",
      "Bata135.jpg-----Clarks\n",
      "Bata145.jpg-----Clarks\n",
      "Bata15.jpg-----Bata\n",
      "Bata155.jpg-----Bata\n",
      "Bata165.jpg-----Leecooper\n",
      "Bata175.jpg-----Bata\n",
      "Bata185.jpg-----Bata\n",
      "Bata195.jpg-----Bata\n",
      "Bata205.jpg-----Bata\n",
      "Bata215.jpg-----Clarks\n",
      "Bata225.jpg-----Bata\n",
      "Bata235.jpg-----Bata\n",
      "Bata245.jpg-----Clarks\n",
      "Bata25.jpg-----Clarks\n",
      "Bata255.jpg-----Bata\n",
      "Bata265.jpg-----Clarks\n",
      "Bata275.jpg-----Bata\n",
      "Bata285.jpg-----Bata\n",
      "Bata295.jpg-----Bata\n",
      "Bata305.jpg-----Clarks\n",
      "Bata315.jpg-----Bata\n",
      "Bata325.jpg-----Clarks\n",
      "Bata335.jpg-----Bata\n",
      "Bata345.jpg-----Bata\n",
      "Bata35.jpg-----Bata\n",
      "Bata355.jpg-----Bata\n",
      "Bata365.jpg-----Bata\n",
      "Bata375.jpg-----Bata\n",
      "Bata385.jpg-----Leecooper\n",
      "Bata415.jpg-----Clarks\n",
      "Bata45.jpg-----Bata\n",
      "Bata5.jpg-----Bata\n",
      "Bata55.jpg-----Bata\n",
      "Bata65.jpg-----Bata\n",
      "Bata75.jpg-----Bata\n",
      "Bata85.jpg-----Bata\n",
      "Bata95.jpg-----Bata\n",
      "total number of images : 41\n",
      " Correctly predicted Images : 29\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "total_count=1\n",
    "count=1\n",
    "os.chdir(\"C:\\\\Users\\\\Administrator\\\\project_internship\\\\dataset\\\\valid\\\\bata\")\n",
    "for filename in os.listdir():\n",
    "    #print(filename)\n",
    "    i=image.load_img(filename,target_size=(40,40))\n",
    "    i=image.img_to_array(i)\n",
    "\n",
    "    i=i.reshape((1,40,40,3))\n",
    "\n",
    "    #i= preprocess_input(i)\n",
    "    result = classfier.predict(i)\n",
    "    #print(result)\n",
    "\n",
    "    result=np.argmax(result)\n",
    "    if result == 0:\n",
    "        count=count+1\n",
    "        prediction=\"Bata\"\n",
    "    elif result==1:\n",
    "        prediction=\"Clarks\"\n",
    "    else:\n",
    "        prediction=\"Leecooper\"\n",
    "    print(filename,end=\"-----\")\n",
    "    print(prediction)\n",
    "    total_count=total_count+1\n",
    "print(\"total number of images :\",total_count)\n",
    "print(\" Correctly predicted Images :\",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clark105.jpg-----Bata\n",
      "clark115.jpg-----Clarks\n",
      "clark125.jpg-----Clarks\n",
      "clark135.jpg-----Clarks\n",
      "clark145.jpg-----Clarks\n",
      "clark15.jpg-----Clarks\n",
      "clark155.jpg-----Leecooper\n",
      "clark165.jpg-----Clarks\n",
      "clark175.jpg-----Bata\n",
      "clark185.jpg-----Clarks\n",
      "clark195.jpg-----Clarks\n",
      "clark205.jpg-----Clarks\n",
      "clark235.jpg-----Clarks\n",
      "clark245.jpg-----Clarks\n",
      "clark25.jpg-----Clarks\n",
      "clark255.jpg-----Bata\n",
      "clark35.jpg-----Bata\n",
      "clark45.jpg-----Bata\n",
      "clark5.jpg-----Clarks\n",
      "clark55.jpg-----Clarks\n",
      "clark65.jpg-----Clarks\n",
      "clark75.jpg-----Clarks\n",
      "clark95.jpg-----Clarks\n",
      "total number of images : 24\n",
      " Correctly predicted Images : 18\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "total_count=1\n",
    "count=1\n",
    "os.chdir(\"C:\\\\Users\\\\Administrator\\\\project_internship\\\\dataset\\\\valid\\\\clarks\")\n",
    "for filename in os.listdir():\n",
    "    #print(filename)\n",
    "    i=image.load_img(filename,target_size=(40,40))\n",
    "    i=image.img_to_array(i)\n",
    "\n",
    "    i=i.reshape((1,40,40,3))\n",
    "\n",
    "    #i= preprocess_input(i)\n",
    "    result = classfier.predict(i)\n",
    "    #print(result)\n",
    "\n",
    "    result=np.argmax(result)\n",
    "    if result == 0:\n",
    "        \n",
    "        prediction=\"Bata\"\n",
    "    elif result==1:\n",
    "        count=count+1\n",
    "        prediction=\"Clarks\"\n",
    "    else:\n",
    "        prediction=\"Leecooper\"\n",
    "    print(filename,end=\"-----\")\n",
    "    print(prediction)\n",
    "    total_count=total_count+1\n",
    "print(\"total number of images :\",total_count)\n",
    "print(\" Correctly predicted Images :\",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leecooper105.jpg-----Clarks\n",
      "leecooper115.jpg-----Leecooper\n",
      "leecooper125.jpg-----Clarks\n",
      "leecooper135.jpg-----Clarks\n",
      "leecooper145.jpg-----Bata\n",
      "leecooper15.jpg-----Clarks\n",
      "leecooper155.jpg-----Clarks\n",
      "leecooper165.jpg-----Bata\n",
      "leecooper175.jpg-----Bata\n",
      "leecooper185.jpg-----Leecooper\n",
      "leecooper195.jpg-----Clarks\n",
      "leecooper205.jpg-----Bata\n",
      "leecooper225.jpg-----Bata\n",
      "leecooper235.jpg-----Bata\n",
      "leecooper25.jpg-----Leecooper\n",
      "leecooper35.jpg-----Bata\n",
      "leecooper45.jpg-----Leecooper\n",
      "leecooper5.jpg-----Leecooper\n",
      "leecooper55.jpg-----Clarks\n",
      "leecooper65.jpg-----Clarks\n",
      "leecooper75.jpg-----Clarks\n",
      "leecooper95.jpg-----Bata\n",
      "total number of images : 23\n",
      " Correctly predicted Images : 6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "total_count=1\n",
    "count=1\n",
    "os.chdir(\"C:\\\\Users\\\\Administrator\\\\project_internship\\\\dataset\\\\valid\\\\leecooper\")\n",
    "for filename in os.listdir():\n",
    "    #print(filename)\n",
    "    i=image.load_img(filename,target_size=(40,40))\n",
    "    i=image.img_to_array(i)\n",
    "\n",
    "    i=i.reshape((1,40,40,3))\n",
    "\n",
    "    #i= preprocess_input(i)\n",
    "    result = classfier.predict(i)\n",
    "    #print(result)\n",
    "\n",
    "    result=np.argmax(result)\n",
    "    if result == 0:\n",
    "        \n",
    "        prediction=\"Bata\"\n",
    "    elif result==1:\n",
    "        prediction=\"Clarks\"\n",
    "    else:\n",
    "        count=count+1\n",
    "        prediction=\"Leecooper\"\n",
    "    print(filename,end=\"-----\")\n",
    "    print(prediction)\n",
    "    total_count=total_count+1\n",
    "print(\"total number of images :\",total_count)\n",
    "print(\" Correctly predicted Images :\",count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
